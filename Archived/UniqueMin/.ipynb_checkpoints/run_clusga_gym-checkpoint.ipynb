{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: MKL_DEBUG_CPU_TYPE=5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "# %env CUDA_LAUNCH_BLOCKING=1\n",
    "%env MKL_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env MKL_DEBUG_CPU_TYPE=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 08:20:14.971108: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-06-28 08:20:14.996519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2399990000 Hz\n",
      "2022-06-28 08:20:14.999417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5a28000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-28 08:20:14.999472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-06-28 08:20:15.003805: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia/hpc_sdk/Linux_x86_64/21.2/compilers/extras/qd/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/11.2/nccl/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/openmpi/openmpi-3.1.5/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/11.2/nccl/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/compilers/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/cuda/11.2/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/math_libs/11.2/lib64:\n",
      "2022-06-28 08:20:15.003857: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-28 08:20:15.003909: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (catgym-0): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and wrap a monitor around it that will periodically record movies as it learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from clusgym_env_unique_minima  import MCSEnv\n",
    "from callback_simple import Callback\n",
    "from tensorforce.execution import Runner\n",
    "import gym.wrappers \n",
    "import numpy as np\n",
    "import tensorforce\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 500\n",
    "num_parallel = 32\n",
    "seed = 30\n",
    "eleNames = ['Ni']\n",
    "eleNums = [8]\n",
    "clus_seed = 22\n",
    "save_dir = './result_multi_env/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial energy 10.869043434917675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gym/wrappers/monitor.py:86: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "def setup_env(recording=True, structure=None, structure_idx=None):\n",
    "    \n",
    "    # Set up gym\n",
    "    MCS_gym = MCSEnv(eleNames=eleNames,\n",
    "                     eleNums=eleNums,\n",
    "                     clus_seed=clus_seed,\n",
    "                     observation_fingerprints=True, \n",
    "                     save_dir = save_dir,\n",
    "                     timesteps = timesteps,\n",
    "                     save_every = 1,\n",
    "                    )\n",
    "    \n",
    "    if recording:\n",
    "    # Wrap the gym to provide video rendering every 50 steps\n",
    "        MCS_gym = gym.wrappers.Monitor(MCS_gym, \n",
    "                                         os.path.join(save_dir, 'vid'), \n",
    "                                         force=True,\n",
    "                                        video_callable = lambda episode_id: (episode_id+1)%30==0) #every 50, starting at 51\n",
    "    \n",
    "    #Convert gym to tensorforce environment\n",
    "    env = tensorforce.environments.OpenAIGym(MCS_gym,\n",
    "                                         max_episode_timesteps=timesteps,\n",
    "                                         visualize=False)\n",
    "    \n",
    "    return env\n",
    "    \n",
    "env = setup_env().environment.env\n",
    "print('initial energy', env.initial_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='Ni8', pbc=True, cell=[23.589055235986407, 21.924528053324284, 22.81526410634917], calculator=EMT(...))\n",
      "[[ 9.79075354 11.56469007 11.62279414]\n",
      " [12.10982611 10.83465163 11.22962706]\n",
      " [10.95457138 10.54828253 13.50197195]\n",
      " [10.40111965 10.46016502  9.59536199]\n",
      " [11.64765603 12.71606833 12.67500097]\n",
      " [10.33324292  9.16631064 11.60016601]\n",
      " [12.51219405  8.90753965 12.6340838 ]\n",
      " [13.30519983 11.0799885  13.32310149]]\n"
     ]
    }
   ],
   "source": [
    "print(env.atoms)\n",
    "print(env.atoms.get_positions())\n",
    "from ase.io import write\n",
    "write(\"initial_clus.traj\", env.atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and agent in tensorforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorforce/core/module.py:698: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from tensorforce.agents import Agent\n",
    "tf.random.set_seed(seed)\n",
    "agent = Agent.create(\n",
    "    agent=dict(type='trpo'),\n",
    "#     agent=dict(type='trpo', critic_network='auto', critic_optimizer=1.0),\n",
    "    environment=setup_env(), \n",
    "    batch_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    memory = 50000,\n",
    "#     memory = dict(type='replay',capacity=10000),\n",
    "    max_episode_timesteps = timesteps,\n",
    "    exploration=dict(\n",
    "        type='decaying', unit='timesteps', decay='exponential',\n",
    "        initial_value=0.2, decay_steps=50000, decay_rate=0.5 #10000, 1000000\n",
    "    ),\n",
    "    \n",
    "    parallel_interactions = num_parallel,\n",
    "    \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DRL method in parallel (multiple environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_episodes = num_parallel*640\n",
    "callback = Callback(save_dir).episode_finish\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    environments=[setup_env(recording=False) for _ in range(num_parallel)],\n",
    "    num_parallel=num_parallel,\n",
    "    remote='multiprocessing',\n",
    "    max_episode_timesteps=timesteps,\n",
    ")\n",
    "\n",
    "#runner.run(num_episodes=num_parallel*250, callback=callback, callback_episode_frequency=1)\n",
    "runner.run(num_episodes=num_episodes, callback=callback, callback_episode_frequency=1)\n",
    "# runner.run(num_episodes=100, evaluation=True)\n",
    "runner.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a single Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Episodes:   0%|          | 0/10000 [00:00, reward=0.00, ts/ep=0, sec/ep=0.00, ms/ts=0.0, agent=0.0%]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MCSEnv' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m runner2 \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m      5\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m      6\u001b[0m     environment\u001b[38;5;241m=\u001b[39msetup_env(recording\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m      7\u001b[0m     max_episode_timesteps\u001b[38;5;241m=\u001b[39mtimesteps,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# %prun runner.run(num_episodes=5, callback=callback, callback_episode_frequency=1)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# callback_episode_frequency --> saving results and trajs frequency\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrunner2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_episode_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/execution/runner.py:516\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, num_episodes, num_timesteps, num_updates, batch_agent_calls, sync_timesteps, sync_episodes, num_sleep_secs, callback, callback_episode_frequency, callback_timestep_frequency, use_tqdm, mean_horizon, evaluation, save_best_agent, evaluation_callback)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# Check whether environment is ready, otherwise continue\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals[n] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_terminals[n]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/environments/environment.py:330\u001b[0m, in \u001b[0;36mEnvironment.receive_execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expect_receive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m states, terminal, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m states, \u001b[38;5;28mint\u001b[39m(terminal), reward\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/environments/environment.py:377\u001b[0m, in \u001b[0;36mEnvironmentWrapper.execute\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TensorforceError(\n\u001b[1;32m    374\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn environment episode has to be initialized by calling reset() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timestep \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_timesteps\n\u001b[0;32m--> 377\u001b[0m states, terminal, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(terminal)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timestep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/environments/openai_gym.py:225\u001b[0m, in \u001b[0;36mOpenAIGym.execute\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m    224\u001b[0m actions \u001b[38;5;241m=\u001b[39m OpenAIGym\u001b[38;5;241m.\u001b[39munflatten_action(action\u001b[38;5;241m=\u001b[39mactions)\n\u001b[0;32m--> 225\u001b[0m states, reward, terminal, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_episode_steps:\n",
      "File \u001b[0;32m~/DRL/ClusGA_Gym/UniqueMin/clusgym_env_unique_minima.py:212\u001b[0m, in \u001b[0;36mMCSEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_episode()\n\u001b[0;32m--> 212\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_traj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, reward, episode_over, {}\n",
      "File \u001b[0;32m~/DRL/ClusGA_Gym/UniqueMin/clusgym_env_unique_minima.py:269\u001b[0m, in \u001b[0;36mMCSEnv.save_traj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_traj\u001b[39m(\u001b[38;5;28mself\u001b[39m):      \n\u001b[1;32m    266\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_full.traj\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminima[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergies\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_idx]\n\u001b[1;32m    267\u001b[0m                                                                   , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_energy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_reward))\n\u001b[1;32m    268\u001b[0m     episode_min_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_min_traj_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m_full.traj\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_minima)\n\u001b[0;32m--> 269\u001b[0m                                                                   , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_energy, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_minima_energies), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_reward))\n\u001b[1;32m    271\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m atoms \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrajectories:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MCSEnv' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "\n",
    "#plot_frequency --> plotting energy and trajectories frequency\n",
    "callback = Callback(save_dir).episode_finish\n",
    "\n",
    "runner2 = Runner(\n",
    "    agent=agent,\n",
    "    environment=setup_env(recording=False),\n",
    "    max_episode_timesteps=timesteps,\n",
    ")\n",
    "\n",
    "# %prun runner.run(num_episodes=5, callback=callback, callback_episode_frequency=1)\n",
    "\n",
    "# callback_episode_frequency --> saving results and trajs frequency\n",
    "runner2.run(num_episodes=10000, callback=callback, callback_episode_frequency=1)\n",
    "# runner2.run(num_episodes=100, evaluation=True)\n",
    "# runner2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
