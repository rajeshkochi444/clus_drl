{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: MKL_DEBUG_CPU_TYPE=5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "# %env CUDA_LAUNCH_BLOCKING=1\n",
    "%env MKL_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env MKL_DEBUG_CPU_TYPE=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 14:07:17.063509: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-07-05 14:07:17.092518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2399990000 Hz\n",
      "2022-07-05 14:07:17.095488: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4464000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-05 14:07:17.095546: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-05 14:07:17.100003: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia/hpc_sdk/Linux_x86_64/21.2/compilers/extras/qd/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/11.2/nccl/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/openmpi/openmpi-3.1.5/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/comm_libs/11.2/nccl/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/compilers/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/cuda/11.2/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.2/math_libs/11.2/lib64:\n",
      "2022-07-05 14:07:17.100052: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-05 14:07:17.100099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (catgym-0): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and wrap a monitor around it that will periodically record movies as it learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from clusgym_env_seperate  import MCSEnv\n",
    "from callback_simple import Callback\n",
    "from tensorforce.execution import Runner\n",
    "import gym.wrappers \n",
    "import numpy as np\n",
    "import tensorforce\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 250\n",
    "num_parallel = 32\n",
    "seed = 30\n",
    "eleNames = ['Cu']\n",
    "eleNums = [13]\n",
    "clus_seed = 10\n",
    "save_dir = './result_multi_env/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial energy 11.017307391796901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gym/wrappers/monitor.py:86: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "def setup_env(recording=True, structure=None, structure_idx=None):\n",
    "    \n",
    "    # Set up gym\n",
    "    MCS_gym = MCSEnv(eleNames=eleNames,\n",
    "                     eleNums=eleNums,\n",
    "                     clus_seed=clus_seed,\n",
    "                     observation_fingerprints=True, \n",
    "                     save_dir = save_dir,\n",
    "                     timesteps = timesteps,\n",
    "                     save_every = 1,\n",
    "                    )\n",
    "    \n",
    "    if recording:\n",
    "    # Wrap the gym to provide video rendering every 50 steps\n",
    "        MCS_gym = gym.wrappers.Monitor(MCS_gym, \n",
    "                                         os.path.join(save_dir, 'vid'), \n",
    "                                         force=True,\n",
    "                                        video_callable = lambda episode_id: (episode_id+1)%30==0) #every 50, starting at 51\n",
    "    \n",
    "    #Convert gym to tensorforce environment\n",
    "    env = tensorforce.environments.OpenAIGym(MCS_gym,\n",
    "                                         max_episode_timesteps=timesteps,\n",
    "                                         visualize=False)\n",
    "    \n",
    "    return env\n",
    "    \n",
    "env = setup_env().environment.env\n",
    "print('initial energy', env.initial_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='Cu13', pbc=True, cell=[24.561300752739605, 22.593173097036605, 26.06466150545518], calculator=EMT(...))\n",
      "[[11.92143228 11.73350783 11.49998517]\n",
      " [13.56683926 11.1972832  13.31600546]\n",
      " [10.43962072 11.23342946 13.41089791]\n",
      " [12.02828104 10.19775862 14.96579692]\n",
      " [14.33754228 11.46616745 10.96974537]\n",
      " [12.07230434 11.03871837 17.24271733]\n",
      " [10.8215311  12.29004966 15.60929734]\n",
      " [12.74248078 11.92455947  9.2195342 ]\n",
      " [13.29835329 12.2575949  15.56130216]\n",
      " [14.3102329   9.25361649 12.02119122]\n",
      " [12.03197491 13.08126347 13.61307475]\n",
      " [11.93022225  9.45970182 12.56437728]\n",
      " [12.7234024   9.73645019 10.23333613]]\n"
     ]
    }
   ],
   "source": [
    "print(env.atoms)\n",
    "print(env.atoms.get_positions())\n",
    "from ase.io import write\n",
    "write(\"initial_clus.traj\", env.atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the gym and agent in tensorforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorforce/core/module.py:698: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from tensorforce.agents import Agent\n",
    "tf.random.set_seed(seed)\n",
    "agent = Agent.create(\n",
    "    agent=dict(type='trpo'),\n",
    "#     agent=dict(type='trpo', critic_network='auto', critic_optimizer=1.0),\n",
    "    environment=setup_env(), \n",
    "    batch_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    memory = 50000,\n",
    "#     memory = dict(type='replay',capacity=10000),\n",
    "    max_episode_timesteps = timesteps,\n",
    "    exploration=dict(\n",
    "        type='decaying', unit='timesteps', decay='exponential',\n",
    "        initial_value=0.2, decay_steps=50000, decay_rate=0.5 #10000, 1000000\n",
    "    ),\n",
    "    \n",
    "    parallel_interactions = num_parallel,\n",
    "    \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DRL method in parallel (multiple environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 0/32000 [00:00, reward=0.00, ts/ep=0, sec/ep=0.00, ms/ts=0.0, agent=0.0%, comm=0.0%]/home/jovyan/DRL/ClusGA_Gym/Seperate_Rewards/Reward3/clusgym_env_seperate.py:166: RuntimeWarning: overflow encountered in exp\n",
      "  reward += 10 * np.exp(-1/self.relative_energy)\n",
      "Episodes:   0%|          | 1/32000 [00:09, reward=9829091947494052973949964376719419676267677556148648607092888013181277647512401733610373120.00, ts/ep=1, sec/ep=9.11, ms/ts=9111.3, agent=69.5%, comm=14.7%]"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m      5\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m      6\u001b[0m     environments\u001b[38;5;241m=\u001b[39m[setup_env(recording\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_parallel)],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     max_episode_timesteps\u001b[38;5;241m=\u001b[39mtimesteps,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#runner.run(num_episodes=num_parallel*250, callback=callback, callback_episode_frequency=1)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_episode_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# runner.run(num_episodes=100, evaluation=True)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m runner\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/execution/runner.py:546\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, num_episodes, num_timesteps, num_updates, batch_agent_calls, sync_timesteps, sync_episodes, num_sleep_secs, callback, callback_episode_frequency, callback_timestep_frequency, use_tqdm, mean_horizon, evaluation, save_best_agent, evaluation_callback)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_act(parallel\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;66;03m# Observe\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_observe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals[n] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;66;03m# Act\u001b[39;00m\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_act(parallel\u001b[38;5;241m=\u001b[39mn)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/execution/runner.py:654\u001b[0m, in \u001b[0;36mRunner.handle_observe\u001b[0;34m(self, parallel)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_agent_calls:\n\u001b[1;32m    653\u001b[0m     agent_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 654\u001b[0m     updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mterminal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_agent_second[parallel] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m agent_start\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(updated)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/agent.py:629\u001b[0m, in \u001b[0;36mAgent.observe\u001b[0;34m(self, reward, terminal, parallel, query, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, reward, terminal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    Observes reward and whether a terminal state is reached, needs to be preceded by\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    `act(...)`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m        values if requested.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m util\u001b[38;5;241m.\u001b[39mreduce_all(predicate\u001b[38;5;241m=\u001b[39mutil\u001b[38;5;241m.\u001b[39mnot_nan_inf, xs\u001b[38;5;241m=\u001b[39mreward)\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_interactions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TensorforceError\u001b[38;5;241m.\u001b[39minvalid(\n\u001b[1;32m    633\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent.observe\u001b[39m\u001b[38;5;124m'\u001b[39m, argument\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel_interactions > 1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    634\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_episodes = num_parallel*1000\n",
    "callback = Callback(save_dir).episode_finish\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    environments=[setup_env(recording=False) for _ in range(num_parallel)],\n",
    "    num_parallel=num_parallel,\n",
    "    remote='multiprocessing',\n",
    "    max_episode_timesteps=timesteps,\n",
    ")\n",
    "\n",
    "#runner.run(num_episodes=num_parallel*250, callback=callback, callback_episode_frequency=1)\n",
    "runner.run(num_episodes=num_episodes, callback=callback, callback_episode_frequency=1)\n",
    "# runner.run(num_episodes=100, evaluation=True)\n",
    "runner.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a single Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#plot_frequency --> plotting energy and trajectories frequency\n",
    "callback = Callback(save_dir).episode_finish\n",
    "\n",
    "runner2 = Runner(\n",
    "    agent=agent,\n",
    "    environment=setup_env(recording=False),\n",
    "    max_episode_timesteps=timesteps,\n",
    ")\n",
    "\n",
    "# %prun runner.run(num_episodes=2, callback=callback, callback_episode_frequency=1)\n",
    "\n",
    "# callback_episode_frequency --> saving results and trajs frequency\n",
    "runner2.run(num_episodes=10000, callback=callback, callback_episode_frequency=1)\n",
    "# runner2.run(num_episodes=100, evaluation=True)\n",
    "# runner2.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
